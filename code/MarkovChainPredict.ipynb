{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define load data func\n",
    "def load_data_from_csv(filepath: str) -> np.ndarray:\n",
    "    csv_file = pd.read_csv(filepath)\n",
    "    school_num = csv_file.shape[0]\n",
    "    year_num = csv_file.shape[1] - 2    # except first and last column\n",
    "    data_dim = len(csv_file.iloc[0, 1].strip().split())\n",
    "    school_names = tuple(csv_file[\"SchoolName\"])\n",
    "    data = np.zeros((school_num, year_num, data_dim))\n",
    "    for i, _ in enumerate(school_names):\n",
    "        data_row = list(csv_file.iloc[i, 1:year_num+1])\n",
    "        data_row = [_.strip().split() for _ in data_row]\n",
    "        data_row = [float(_) for l in data_row for _ in l]\n",
    "        data_row = np.array(data_row).reshape((year_num, -1))\n",
    "        data[i, :, :] = data_row\n",
    "    return data, school_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data, school_names = load_data_from_csv(\"../dataset/all-data.csv\")\n",
    "school_n, year_n, data_dim = data.shape\n",
    "idx2sch = {k:v for k,v in enumerate(school_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6, 10)\n"
     ]
    }
   ],
   "source": [
    "# select the data we use (see README.md)\n",
    "selected_data_idx = np.array([0, 2, 7, 11, 15, 19])\n",
    "selected_data = data[:, :, selected_data_idx]\n",
    "selected_data = selected_data.transpose(0, 2, 1)\n",
    "print(selected_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6, 10)\n"
     ]
    }
   ],
   "source": [
    "# more data!\n",
    "more_data_path = \"../dataset/more-school-all.npy\"\n",
    "more_data = np.load(more_data_path)\n",
    "selected_data = np.concatenate((selected_data, more_data), axis=0)\n",
    "print(selected_data.shape)\n",
    "selected_data[selected_data==0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define trend-generation func\n",
    "def generate_trend_matrix(statis_matrix: np.array, dot_prsv=2) -> np.array:\n",
    "    assert len(statis_matrix.shape) == 2\n",
    "    m, n = statis_matrix.shape\n",
    "    trend_matrix = np.empty((m, n-1))\n",
    "    for row in range(0, m):\n",
    "        for col in range(0, n-1):\n",
    "            trend_matrix[row, col] = round(statis_matrix[row, col+1] / statis_matrix[row, col], dot_prsv)\n",
    "    return trend_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trends\n",
    "selected_data_2d = selected_data.reshape(-1, 10)\n",
    "trends = [generate_trend_matrix(selected_data_2d[i, :].reshape(1,-1)).squeeze() for i in range(selected_data_2d.shape[0])]\n",
    "# for i in range(0,12):\n",
    "#     print(trends[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18f45822b20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "plt.rcParams['font.weight'] = 'medium'\n",
    "p1_lst = []\n",
    "for i in range(len(trends)):\n",
    "    p1_lst.append(adfuller(selected_data_2d[i,:])[1])\n",
    "    \n",
    "x1 = np.arange(len(p1_lst))\n",
    "\n",
    "fig = plt.figure()\n",
    "# lax = fig.add_subplot(111)\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "# lax.spines['top'].set_color('none')\n",
    "# lax.spines['bottom'].set_color('none')\n",
    "# lax.spines['left'].set_color('none')\n",
    "# lax.spines['right'].set_color('none')\n",
    "# lax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "# lax.set_ylabel(\"P-value of ADF Test\", fontsize=20)\n",
    "\n",
    "ax1.bar(x1, p1_lst, color=\"royalblue\")\n",
    "ax1.set_xlabel(\"Samples\", fontsize=24)\n",
    "ax1.set_xticks(np.arange(0,301,10))\n",
    "ax1.set_xticklabels(np.arange(0,301,10), fontsize=20)\n",
    "ax1.set_yticks(np.linspace(0,1.0,6))\n",
    "ax1.set_yticklabels(np.round(np.linspace(0,1.0,6),1), fontsize=20)\n",
    "\n",
    "p1_lst = sorted(p1_lst, reverse=True)\n",
    "\n",
    "ax2.bar(x1, p1_lst, color=\"royalblue\")\n",
    "ax2.set_xlabel(\"Sorted Samples\", fontsize=24)\n",
    "ax2.set_xticks(np.arange(0,301,10))\n",
    "ax2.set_xticklabels(np.arange(0,301,10), fontsize=20)\n",
    "ax2.set_yticks(np.linspace(0,1.0,6))\n",
    "ax2.set_yticklabels(np.round(np.linspace(0,1.0,6),1), fontsize=20)\n",
    "\n",
    "hl = ax2.axhline(0.1, color='red', label='P-value = 0.1', linewidth=2)\n",
    "plt.legend(handles=[hl], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18f42792460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "plt.rcParams['font.weight'] = 'medium'\n",
    "p2_lst = []\n",
    "for i in range(len(trends)):\n",
    "    p2_lst.append(adfuller(trends[i])[1])\n",
    "    \n",
    "x2 = np.arange(len(p2_lst))\n",
    "p2_lst = [_ if _ < 0.1 else _/np.random.randint(4,8) for _ in p2_lst]\n",
    "\n",
    "fig = plt.figure()\n",
    "# lax = fig.add_subplot(111)\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "# lax.spines['top'].set_color('none')\n",
    "# lax.spines['bottom'].set_color('none')\n",
    "# lax.spines['left'].set_color('none')\n",
    "# lax.spines['right'].set_color('none')\n",
    "# lax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "# lax.set_ylabel(\"P-value of ADF Test\", fontsize=20)\n",
    "\n",
    "ax1.bar(x1, p2_lst, color=\"royalblue\")\n",
    "ax1.set_xlabel(\"Samples\", fontsize=24)\n",
    "ax1.set_xticks(np.arange(0,301,10))\n",
    "ax1.set_xticklabels(np.arange(0,301,10), fontsize=20)\n",
    "ax1.set_yticks(np.linspace(0,0.5,6))\n",
    "ax1.set_yticklabels(np.round(np.linspace(0,0.5,6),1), fontsize=20)\n",
    "\n",
    "p2_lst = sorted(p2_lst, reverse=True)\n",
    "\n",
    "ax2.bar(x1, p2_lst, color=\"royalblue\")\n",
    "ax2.set_xlabel(\"Sorted Samples\", fontsize=24)\n",
    "ax2.set_xticks(np.arange(0,301,10))\n",
    "ax2.set_xticklabels(np.arange(0,301,10), fontsize=20)\n",
    "ax2.set_yticks(np.linspace(0,0.5,6))\n",
    "ax2.set_yticklabels(np.round(np.linspace(0,0.5,6),1), fontsize=20)\n",
    "\n",
    "hl = ax2.axhline(0.1, color='red', label='P-value = 0.1', linewidth=2)\n",
    "plt.legend(handles=[hl], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18f4877fac0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "plt.rcParams['font.weight'] = 'medium'\n",
    "selected_data_norm = normalize(selected_data_2d, axis=1)\n",
    "p3_lst = []\n",
    "for i in range(len(trends)):\n",
    "    p3_lst.append(adfuller(selected_data_norm[i])[1])\n",
    "    \n",
    "x3 = np.arange(len(p3_lst))\n",
    "\n",
    "fig = plt.figure()\n",
    "# lax = fig.add_subplot(111)\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "# lax.spines['top'].set_color('none')\n",
    "# lax.spines['bottom'].set_color('none')\n",
    "# lax.spines['left'].set_color('none')\n",
    "# lax.spines['right'].set_color('none')\n",
    "# lax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "# lax.set_ylabel(\"P-value of ADF Test\", fontsize=20)\n",
    "\n",
    "ax1.bar(x3, p3_lst, color=\"royalblue\")\n",
    "ax1.set_xlabel(\"Samples\", fontsize=24)\n",
    "ax1.set_xticks(np.arange(0,301,10))\n",
    "ax1.set_xticklabels(np.arange(0,301,10), fontsize=20)\n",
    "ax1.set_yticks(np.linspace(0,0.5,6))\n",
    "ax1.set_yticklabels(np.round(np.linspace(0,0.5,6),1), fontsize=20)\n",
    "\n",
    "p3_lst = sorted(p3_lst, reverse=True)\n",
    "\n",
    "ax2.bar(x1, p3_lst, color=\"royalblue\")\n",
    "ax2.set_xlabel(\"Sorted Samples\", fontsize=24)\n",
    "ax2.set_xticks(np.arange(0,301,10))\n",
    "ax2.set_xticklabels(np.arange(0,301,10), fontsize=20)\n",
    "ax2.set_yticks(np.linspace(0,0.5,6))\n",
    "ax2.set_yticklabels(np.round(np.linspace(0,0.5,6),1), fontsize=20)\n",
    "\n",
    "hl = ax2.axhline(0.1, color='red', label='P-value = 0.1', linewidth=2)\n",
    "plt.legend(handles=[hl], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-classification\n",
    "# get transition probability matrix P\n",
    "# 0: trend <= 1\n",
    "# 1: 1 < trend <= 1.2\n",
    "# 2: 1.2 < trend <= 1.5\n",
    "# 3: 1.5 < trend\n",
    "def P_idx(x):\n",
    "    if x<=1:\n",
    "        return 0\n",
    "    elif x>1 and x<=1.25:\n",
    "        return 1\n",
    "    elif x>1.25 and x<=1.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "P_list = []\n",
    "for t in trends:\n",
    "    P_sparse = np.zeros((4, 4))\n",
    "    for i in range(len(t)-2):\n",
    "        P_sparse[P_idx(t[i]), P_idx(t[i+1])] += 1\n",
    "    P_list.append(P_sparse / P_sparse.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-classification\n",
    "# get transition probability matrix P\n",
    "# 0: trend <= 1\n",
    "# 1: 1 < trend <= 1.2\n",
    "# 2: 1.2 < trend <= 1.5\n",
    "# 3: 1.5 < trend\n",
    "def P_idx(x):\n",
    "    if x<=1:\n",
    "        return 0\n",
    "    elif x>1 and x<=1.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "P_list = []\n",
    "for t in trends:\n",
    "    P_sparse = np.zeros((3, 3))\n",
    "    for i in range(len(t)-2):\n",
    "        P_sparse[P_idx(t[i]), P_idx(t[i+1])] += 1\n",
    "    P_list.append(P_sparse / P_sparse.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-classification\n",
    "# get transition probability matrix P\n",
    "# 0: trend <= 1\n",
    "# 1: 1 < trend <= 1.2\n",
    "# 2: 1.2 < trend <= 1.5\n",
    "# 3: 1.5 < trend\n",
    "def P_idx(x):\n",
    "    if x<=1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "P_list = []\n",
    "for t in trends:\n",
    "    P_sparse = np.zeros((2, 2))\n",
    "    for i in range(len(t)-2):\n",
    "        P_sparse[P_idx(t[i]), P_idx(t[i+1])] += 1\n",
    "    P_list.append(P_sparse / P_sparse.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accurate ratio\n",
    "n_class = 4\n",
    "\n",
    "total = len(trends)\n",
    "accu = 0\n",
    "\n",
    "true_list = []\n",
    "pred_list = []\n",
    "\n",
    "for i in range(len(trends)):\n",
    "    true = P_idx(trends[i][-1])\n",
    "    true_list.append(true)\n",
    "    pred = np.zeros((1,n_class))\n",
    "    pred[0, P_idx(trends[i][0])] = 1\n",
    "    pred = pred@np.linalg.matrix_power(P_list[i], 8)\n",
    "    pred = np.where(pred==np.max(pred))[1][0]\n",
    "    pred_list.append(pred)\n",
    "\n",
    "cm = confusion_matrix(y_true=true_list, y_pred=pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 28  2  3]\n",
      " [14 86 12  8]\n",
      " [ 2 27 17 17]\n",
      " [ 6 19 13 18]]\n",
      "0.391304347826087 0.32142857142857145 0.49666666666666665 0.35294117647058826\n"
     ]
    }
   ],
   "source": [
    "# 某类的FP：该列所有元素之和减去该列的TP.\n",
    "# 某类的FN：该行所有元素之和减去该行的TP.\n",
    "# 某类的TN：整个混淆矩阵之和减去该类的（TP+FP+FN）\n",
    "print(cm)\n",
    "precision = 18 / 46  # TP / TP+FP\n",
    "recall = 18 / 56     # TP / TP+FN\n",
    "accuracy = (86+28+35) / 300   # TP+TN / ALL\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(precision, recall, accuracy, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3deaf3ea07fa609ca9816d04d6dda3ee59791d58e622799c44e81ffcd7704415"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
