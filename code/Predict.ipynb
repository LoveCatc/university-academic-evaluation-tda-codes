{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVC, SVC, SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from gtda.time_series import TakensEmbedding\n",
    "from PyEMD import EMD\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pylab import mpl\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_data_path = \"../dataset/top20.npy\"\n",
    "more_data = np.load(more_data_path)\n",
    "selected_data = np.zeros((20,6,12))\n",
    "selected_data[:, 0:2, :] = more_data[:, 0:2, :]\n",
    "# print(selected_data[0,:,:])\n",
    "selected_data[:, 2, :] = more_data[:, 2, :] + more_data[:, 3, :]\n",
    "selected_data[:, 3:6, :] = more_data[:, 4:7, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define trend-generation func\n",
    "def generate_trend_matrix(statis_matrix: np.array, dot_prsv=2) -> np.array:\n",
    "    assert len(statis_matrix.shape) == 2\n",
    "    m, n = statis_matrix.shape\n",
    "    trend_matrix = np.empty((m, n-1))\n",
    "    for row in range(0, m):\n",
    "        for col in range(0, n-1):\n",
    "            if statis_matrix[row, col] != 0:\n",
    "                trend_matrix[row, col] = round(statis_matrix[row, col+1] / statis_matrix[row, col], dot_prsv)\n",
    "            else:\n",
    "                trend_matrix[row, col] = 10\n",
    "    return trend_matrix\n",
    "\n",
    "enhanced_data = []\n",
    "reshaped = selected_data.reshape(-1, 12)\n",
    "for i in range(reshaped.shape[0]):\n",
    "    d = reshaped[i, :]\n",
    "    d = (d-np.mean(d)) / np.std(d)\n",
    "    # ATTENTION\n",
    "    # enhanced_data.append([[d[j], d[j+1], d[j+2]] for j in range(len(d)-3)])\n",
    "    enhanced_data.append([[d[j], d[j+1], d[j+2]] for j in range(len(d)-2)])\n",
    "enhanced_data = np.array(enhanced_data)\n",
    "data_train = enhanced_data[:, :-1, :]\n",
    "data_pred = enhanced_data[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_train = []\n",
    "for i in range(data_train.shape[0]):\n",
    "    r = ripser(data_train[i, :, :])\n",
    "    feature = np.delete(r['dgms'][0], -1, axis=0)[:, 1]\n",
    "    f = [feature.shape[0], np.sum(feature), np.mean(feature), np.std(feature), np.max(feature), np.min(feature), len([_ for _ in feature if _>0.5*np.max(feature)]), len([_ for _ in feature if _>np.mean(feature)])]\n",
    "    f = [np.round(_, 2) for _ in f]\n",
    "    feature_list_train.append(np.array(f))\n",
    "\n",
    "feature_list_pred = []\n",
    "for i in range(data_pred.shape[0]):\n",
    "    r = ripser(data_pred[i, :, :])\n",
    "    feature = np.delete(r['dgms'][0], -1, axis=0)[:, 1]\n",
    "    f = [feature.shape[0], np.sum(feature), np.mean(feature), np.std(feature), np.max(feature), np.min(feature), len([_ for _ in feature if _>0.5*np.max(feature)]), len([_ for _ in feature if _>np.mean(feature)])]\n",
    "    f = [np.round(_, 2) for _ in f]\n",
    "    feature_list_pred.append(np.array(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = np.array([generate_trend_matrix(reshaped[i, :].reshape(1,-1)).squeeze() for i in range(reshaped.shape[0])])\n",
    "trends = trends[:, -1].reshape(-1, 1)\n",
    "feature_pd = pd.DataFrame(np.concatenate((np.array(feature_list_train), trends), axis=1), \\\n",
    "    columns=['Number of TDA barcode points', 'Sum of lifetime', 'Average of lifetime', 'Std of lifetime', 'Max of lifetime', \\\n",
    "        'Min of lifetime', 'Number of points bigger than 0.5*max', 'Number of points bigger than average', 'Trend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77569966 0.83571667 0.62495079 0.64418745 0.90386382 0.88450766]\n",
      " [0.81187243 0.85812683 0.58386582 0.7432048  0.89266048 0.87599745]\n",
      " [0.8331817  0.81740484 0.73653958 0.78845862 0.91043914 0.86237466]\n",
      " [0.80263817 0.79246776 0.59442573 0.75456168 0.76217564 0.88885511]\n",
      " [0.86097902 0.86440656 0.60128859 0.72320102 0.75136294 0.90352131]\n",
      " [0.76890328 0.78641736 0.82374128 0.68147777 0.83070203 0.91551638]\n",
      " [0.82914931 0.80779966 0.82332658 0.90432293 0.88464515 0.79688935]\n",
      " [0.80200187 0.85075846 0.82645473 0.75630487 0.89483996 0.860208  ]\n",
      " [0.76386031 0.82912354 0.68031938 0.77066209 0.8623548  0.89374094]\n",
      " [0.78362542 0.86612149 0.71345049 0.67266642 0.90437083 0.89033003]\n",
      " [0.80521026 0.83022381 0.69925699 0.79761517 0.91951518 0.84913006]\n",
      " [0.86058703 0.81911029 0.76132269 0.84090674 0.83220646 0.83802161]\n",
      " [0.78796672 0.83502795 0.78211941 0.65822784 0.90017277 0.87235794]\n",
      " [0.82584882 0.84076009 0.68563121 0.68794788 0.88485247 0.92006976]\n",
      " [0.83995422 0.85240155 0.56175359 0.76039323 0.93732148 0.89345022]\n",
      " [0.80916505 0.85885765 0.85663862 0.66141926 0.90118113 0.83946027]\n",
      " [0.82088091 0.78632808 0.82038104 0.64458742 0.84904848 0.88376337]\n",
      " [0.84892074 0.81008674 0.81332403 0.88866209 0.80352072 0.87780318]\n",
      " [0.86578302 0.84371183 0.77205649 0.78379562 0.9203218  0.91464995]\n",
      " [0.82871317 0.83077331 0.72852668 0.75723198 0.99163091 0.92343877]]\n"
     ]
    }
   ],
   "source": [
    "X = feature_pd[['Number of TDA barcode points', 'Sum of lifetime', 'Average of lifetime', 'Std of lifetime', 'Max of lifetime', \\\n",
    "        'Min of lifetime', 'Number of points bigger than 0.5*max', 'Number of points bigger than average']]\n",
    "Y = feature_pd[['Trend']]\n",
    "\n",
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()\n",
    "\n",
    "pred = []\n",
    "for i in range(120):\n",
    "    X_test = feature_list_pred[i]\n",
    "    X_train = np.delete(X, i, axis=0)\n",
    "    Y_train = np.delete(Y, i, axis=0)\n",
    "    svr = SVR(C=1.0, epsilon=0.2, kernel='linear')\n",
    "    svr.fit(X_train, np.ravel(Y_train))\n",
    "    pred.append(float(svr.predict(X_test.reshape(1,-1))))\n",
    "\n",
    "print(np.array(pred).reshape(-1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ripser_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d856ea83737ecf31b084a6c4dd25de1f47360aa39d05be84e9035ad6a44a6c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
